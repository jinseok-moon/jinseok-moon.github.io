<!doctype html><html lang=ko dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="GPU는 계속 세대가 발전했고, 그에 따라서 feature들이 바뀌었다. LLM을 다룰것이라면 Ampere 부터의 GPU의 하드웨어적 특성을 알면 좋다. A100, H100 등 각 아키텍쳐의 대표적인 GPU를 통해 알아보자. 텐서코어의 TOPS 같은 성능수치는 다루지 않는다.\nA100: Ampere (SM80, 2020) 2020년 발표된 GPU로, L1 bypass를 통해서 많은 과정이 생략되면서 DRAM의 값을 Shared Memory (SRAM)에 불러오는 것이 최적화되었다.\ncp.async ptx로 구성되는 이 메모리 복사는 비동기적으로 일어나기 때문에 다음과 같은 소프트웨어 파이프라인을 통해서 latency를 숨길 수 있다.\n"><title>GPU Architecture w/ LLM</title><link rel=canonical href=https://jinseok-moon.github.io/ko/p/archs/><link rel=stylesheet href=/scss/style.min.44c91e7e98aee33a9cb385aa3c14716697fe72e9c673e06c0b7b2b5084608b31.css><meta property='og:title' content="GPU Architecture w/ LLM"><meta property='og:description' content="GPU는 계속 세대가 발전했고, 그에 따라서 feature들이 바뀌었다. LLM을 다룰것이라면 Ampere 부터의 GPU의 하드웨어적 특성을 알면 좋다. A100, H100 등 각 아키텍쳐의 대표적인 GPU를 통해 알아보자. 텐서코어의 TOPS 같은 성능수치는 다루지 않는다.\nA100: Ampere (SM80, 2020) 2020년 발표된 GPU로, L1 bypass를 통해서 많은 과정이 생략되면서 DRAM의 값을 Shared Memory (SRAM)에 불러오는 것이 최적화되었다.\ncp.async ptx로 구성되는 이 메모리 복사는 비동기적으로 일어나기 때문에 다음과 같은 소프트웨어 파이프라인을 통해서 latency를 숨길 수 있다.\n"><meta property='og:url' content='https://jinseok-moon.github.io/ko/p/archs/'><meta property='og:site_name' content='Jinseok Moon'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:published_time' content='2025-11-24T00:00:00+00:00'><meta property='article:modified_time' content='2025-11-24T00:00:00+00:00'><meta name=twitter:title content="GPU Architecture w/ LLM"><meta name=twitter:description content="GPU는 계속 세대가 발전했고, 그에 따라서 feature들이 바뀌었다. LLM을 다룰것이라면 Ampere 부터의 GPU의 하드웨어적 특성을 알면 좋다. A100, H100 등 각 아키텍쳐의 대표적인 GPU를 통해 알아보자. 텐서코어의 TOPS 같은 성능수치는 다루지 않는다.\nA100: Ampere (SM80, 2020) 2020년 발표된 GPU로, L1 bypass를 통해서 많은 과정이 생략되면서 DRAM의 값을 Shared Memory (SRAM)에 불러오는 것이 최적화되었다.\ncp.async ptx로 구성되는 이 메모리 복사는 비동기적으로 일어나기 때문에 다음과 같은 소프트웨어 파이프라인을 통해서 latency를 숨길 수 있다.\n"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="메뉴 여닫기">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><div class=site-meta><h1 class=site-name><a href=/ko>Jinseok Moon</a></h1><h2 class=site-description>GPU Software Engineer</h2></div></header><ol class=menu-social><li><a href=https://www.github.com/jinseok-moon target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://www.linkedin.com/in/jinseok-moon target=_blank title=LinkedIn rel=me><svg class="icon icon-tabler icon-tabler-brand-linkedin" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><rect x="4" y="4" width="16" height="16" rx="2"/><path d="M8 11v5"/><path d="M8 8v.01"/><path d="M12 16v-5"/><path d="M16 16v-3a2 2 0 00-4 0"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/ko/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/ko/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/ko/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>다크 모드</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">목차</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#a100-ampere-sm80-2020>A100: Ampere (SM80, 2020)</a></li><li><a href=#h100-hopper-sm90-2022>H100: Hopper (SM90, 2022)</a><ol><li><a href=#tensor-memory-accelerator-tma>Tensor Memory Accelerator (TMA)</a></li><li><a href=#warp-group-matrix-multiply-accumulate-wgmma>Warp Group Matrix Multiply-Accumulate (WGMMA)</a></li><li><a href=#warp-specialization-consumer-producer>Warp Specialization: Consumer-Producer</a></li></ol></li><li><a href=#blackwell-sm100-2024>Blackwell (SM100, 2024)</a><ol><li><a href=#grace-blackwell-gb200>Grace-Blackwell GB200</a></li><li><a href=#blackwell-geforce-rtx-50-series-sm120-2025>Blackwell Geforce RTX 50 series (SM120, 2025)</a></li></ol></li><li><a href=#references>References</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/ko/categories/cuda/ style=background-color:#2a9d8f;color:#fff>cuda</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/ko/p/archs/>GPU Architecture w/ LLM</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published datetime=2025-11-24T00:00:00Z>11월 24, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>3 분 정도</time></div></footer><footer class=article-translations><svg class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg><div><a href=https://jinseok-moon.github.io/p/archs/ class=link>English</a></div></footer></div></header><section class=article-content><p>GPU는 계속 세대가 발전했고, 그에 따라서 feature들이 바뀌었다. LLM을 다룰것이라면 Ampere 부터의 GPU의 하드웨어적 특성을 알면 좋다.
A100, H100 등 각 아키텍쳐의 대표적인 GPU를 통해 알아보자. 텐서코어의 TOPS 같은 성능수치는 다루지 않는다.</p><h2 id=a100-ampere-sm80-2020>A100: Ampere (SM80, 2020)</h2><p>2020년 발표된 GPU로, L1 bypass를 통해서 많은 과정이 생략되면서 DRAM의 값을 Shared Memory (SRAM)에 불러오는 것이 최적화되었다.</p><p><img src=/p/archs/images/image.png width=1880 height=2120 loading=lazy class=gallery-image data-flex-grow=88 data-flex-basis=212px></p><p><code>cp.async</code> ptx로 구성되는 이 메모리 복사는 비동기적으로 일어나기 때문에 다음과 같은 소프트웨어 파이프라인을 통해서 latency를 숨길 수 있다.</p><p><img src=/p/archs/images/image-1.png width=3640 height=1265 loading=lazy class=gallery-image data-flex-grow=287 data-flex-basis=690px></p><p>소프트웨어 파이프라인은 연속된 명령어의 종속성을 제거해서 하드웨어를 fully utilize 하는 기법이다. 메모리 instruction LSU(Load Store Unit)에서 처리되고, 행렬곱은 연산장치(Tensor Core)에서 처리되므로, 하드웨어 종속성은 문제가 되지 않는다. 하지만 다음과 같은 데이터 종속성은 문제가 될 수 있다.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=n>i</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span> <span class=n>i</span><span class=o>&lt;</span><span class=n>N</span><span class=o>-</span><span class=mi>1</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=n>load_to_register</span><span class=p>(</span><span class=n>i</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>compute</span><span class=p>(</span><span class=n>i</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><code>load_to_register(i)</code> 가 완료될 때까지 <code>compute(i)</code> 를 실행할 수 없다. load된 <code>i</code>의 데이터가 필요하기 때문이다. 따라서 파이프라인을 구성한다.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>load_to_register</span><span class=p>(</span><span class=mi>0</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=n>i</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span> <span class=n>i</span><span class=o>&lt;</span><span class=n>N</span><span class=o>-</span><span class=mi>2</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=n>load_to_register</span><span class=p>(</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>compute</span><span class=p>(</span><span class=n>i</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>compute</span><span class=p>(</span><span class=n>N</span><span class=o>-</span><span class=mi>1</span><span class=p>);</span>
</span></span></code></pre></div><p>이렇게 하면 두 instruction 사이에 종속성이 제거되어 동시에 실행할 수 있다. 이 로직을 최대한 활용한 커널이 바로 <code>Flash-Attention-2</code>다. 저자의 말에 따르면 Ampere에서의 이론적 최대 성능에 근접한 값이라고 한다. 다른 포스트에서 설명하겠지만 mixed-precision gemm kernel <code>Marlin</code> 또한 최적화된 커널의 하나다.</p><h2 id=h100-hopper-sm90-2022>H100: Hopper (SM90, 2022)</h2><p>2022년 GTC에서 발표된 Hopper 아키텍쳐이다. Ampere보다 훨씬 좋은 성능이다. 성능의 개선은 크게 TMA, WGMMA, Warp-Specialization 세가지를 다룬다. 미리 언급하면, H100의 feature를 활용한 커널에는 <code>Flash-Attention-3</code>, <code>Machete</code> 등이 있다.</p><h3 id=tensor-memory-accelerator-tma>Tensor Memory Accelerator (TMA)</h3><p>Ampere에서 L1 bypass를 통한 memory instruction의 성능 개선을 이루었다. 하지만 이를 위해서는 직접 메모리 주소와 stride 계산을 해주고 동기화에 관한 barrier까지 모두 관리해주어야했다. 그래서 NVIDIA는 여기에 만족하지 않고 TMA라는 유닛을 개발했다. TMA를 이용하면 텐서의 정보를 이용해서 대량의 데이터를 복사한다. 또한, 이 TMA instruction은 단일 스레드에서 launch되기 때문에 자원을 더욱 효율적으로 사용가능하다.</p><p><img src=/p/archs/images/image-2.png width=1506 height=644 loading=lazy class=gallery-image data-flex-grow=233 data-flex-basis=561px></p><h3 id=warp-group-matrix-multiply-accumulate-wgmma>Warp Group Matrix Multiply-Accumulate (WGMMA)</h3><p>Ampere까지의 mma는 모두 단일 warp 기반 instruction이다. NVIDIA가 극한의 효율을 추구한 결과, 4개의 warp를 묶어서 mma를 처리하도록 만들었다.</p><h3 id=warp-specialization-consumer-producer>Warp Specialization: Consumer-Producer</h3><p>이건 Hopper의 기능을 활용한 테크닉이다.Hopper는 각 warp가 사용할 register 개수를 지정해 줄 수 있게 되었다. 이 정보를 염두하고서 파이프라인을 살펴보면 1) memory 2) computation 의 두가지 큰 줄기가 있다. 당연히 memory instruction에서는 레지스터가 상대적으로 적게 필요할것이다. 분업에 따른 레지스터 차등분배는 다음과 같다.</p><ul><li>Produer warp group. TMA를 활용한 메모리 instruction 담당. 레지스터를 적게 가져도 충분함. 열심히 메모리를 불러옴.</li><li>Consumer warp group. 텐서코어를 활용한 WGMMA isntruction 담당. 레지스터를 많이 가져가서 열심히 연산함.</li></ul><h2 id=blackwell-sm100-2024>Blackwell (SM100, 2024)</h2><p>2024 GTC에서 발표된 차세대 GPU. 이번에도 많은 것이 바뀌었다. 우선, WGMMA는 더이상 사용되지 않는다. Hopper 단일 아키텍쳐 지원 instruction이라니! 대신 UMMA가 생겼다. UMMA는 다음과 같은 입력 조건이 있다.</p><ul><li>Operand A: TMEM or SMEM</li><li>Operand B: SMEM</li><li>Accumulator: TMEM</li></ul><p><img src=/p/archs/images/image-3.png width=1600 height=900 loading=lazy class=gallery-image data-flex-grow=177 data-flex-basis=426px></p><p>Tensor Memory (TMEM), TMEM이 무엇일까? Blackwell에서 새로 생긴 구조로, accumulator가 이곳에 있다는 것은 UMMA에서 데이터 처리를 위해 register가 필요하지 않음을 의미한다.
뭐라고? 단일 스레드 실행에, 레지스터까지 필요없다고? TMA까지 활용하면 CTA(Cooperative Thread Array, 쉽게 말하면 CUDA kernel에서의 블록을 의미)에서 할 일은 전/후처리만 남는다.</p><blockquote><p>과거의 역사적 맥락에서 이러한 발전들은 범용 리소스를 다른 작업에 사용할 수 있도록, 연산들을 특수 하드웨어 리소스로 대체, 분리하는 추세임을 알 수 있겠다.</p><ul><li>Volta: Tensor Core로 행렬 연산을 일반 연산 파이프라인에서 분리</li><li>Ampere: async copy로 데이터 로딩과 계산을 동시에 수행, 진정한 파이프라인화</li><li>Hopper: TMA와 WGMMA로 데이터 이동과 MMA를 비동기, 저비용으로 겹쳐 실행</li><li>Blackwell: TMEM과 UMMA로 MMA 자체를 단일 스레드, 비동기로 처리해 레지스터 부담 제거</li></ul></blockquote><h3 id=grace-blackwell-gb200>Grace-Blackwell GB200</h3><p>NVIDIA의 Grace CPU와 Blackwell GPU를 엮은 아키텍쳐. 위에서 이야기 한 것은 모두 GPU내부에서 일어나는 일들이다. 우리는 host(CPU)로부터 device(GPU)로 메모리를 복사해줄 필요가 있다. 어떻게? 기존에는 PCIe로.. 아 이게 많이 느리다. 그래서 NVLink로 둘을 붙였고, 그래서 Grace Blackwell이다. 당연히 PCIe보다 훨씬 빠를 것.</p><h3 id=blackwell-geforce-rtx-50-series-sm120-2025>Blackwell Geforce RTX 50 series (SM120, 2025)</h3><p>Blackwell 기반의 Geforce GPU다. 참 비싼 가격이 요즘은 조금 내려온 것 같기도..? Blackwell 아키텍쳐지만 위에서 열심히 이야기한 TMEM이 없다. TMA는 있다. 그래서 LLM에 활용하려면 Ampere식 파이프라인에 TMA를 쓰는 정도일 듯 싶지만, 이걸 굳이 할 이유는 별로 없다. 물론 텐서코어 성능은 비교할 수 없이 좋아졌다.</p><h2 id=references>References</h2><ul><li><a class=link href=https://research.colfax-intl.com/cutlass-tutorial-design-of-a-gemm-kernel target=_blank rel=noopener>CUTLASS Tutorial: Efficient GEMM kernel designs with Pipelining</a></li><li><a class=link href=https://research.colfax-intl.com/cutlass-tutorial-writing-gemm-kernels-using-tensor-memory-for-nvidia-blackwell-gpus/ target=_blank rel=noopener>CUTLASS Tutorial: Writing GEMM Kernels Using Tensor Memory For NVIDIA® Blackwell GPUs</a></li></ul></section><footer class=article-footer></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=[".main-article",".widget--toc"];e.forEach(e=>{const t=document.querySelector(e);t&&renderMathInElement(t,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})})</script></article><aside class=related-content--wrapper><h2 class=section-title>관련 글</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/ko/p/cuda-tile/><div class=article-details><h2 class=article-title>CUDA Tile IR, cuTile Python</h2></div></a></article><article><a href=/ko/p/gemm-2/><div class=article-details><h2 class=article-title>GEMM 2</h2></div></a></article><article><a href=/ko/p/gemm-1/><div class=article-details><h2 class=article-title>GEMM 1</h2></div></a></article><article><a href=/ko/p/thread-indexing/><div class=article-details><h2 class=article-title>Proper thread indexing and memory coalescing</h2></div></a></article><article><a href=/ko/p/online-softmax/><div class=article-details><h2 class=article-title>Online softmax</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//myblog-otcr7pydaj.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2024 -
2026 Jinseok Moon</section><section class=powerby><a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a>로 만듦<br><a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a>의 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.33.0>Stack</a></b> 테마 사용 중</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.c922af694cc257bf1ecc41c0dd7b0430f9114ec280ccf67cd2c6ad55f5316c4e.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>