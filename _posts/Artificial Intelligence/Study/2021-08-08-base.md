---
title: "인공지능, 딥러닝 공부에 앞서"
excerpt: "Learn about concept of Deep Learning and CNN"
categories:
  - Study
tags: 
  - [AI]
toc: true
toc_sticky: true
toc_label: "On this page"
published: true
---

## 딥러닝 - 머신러닝 - 인공지능
우리는 '인공지능, 머신러닝, 딥러닝' 이 세가지의 단어를 자주 접한다. 이 세가지는 어떻게 다를까?

<center>
	<figure style="width: 60%"> <img src="/Images/Study/base1.png" alt="AI, ML, DLArtificial Intelligence"/>
    <figcaption>인공지능, 머신러닝, 딥러닝의 차이</figcaption>
    </figure>
</center>

우선 `인공지능(Artificial Intelligence, AI)`은 단어 그대로라고 생각하면 편하다. 스스로 생각해서 무언가 결정을 내리는 것을 인공적으로 만들어 낸 것, 이 폭 넓은 개념이 인공지능이다.
`머신러닝(Machine Learning, ML)`은 인공지능 범주 안에 속하는 개념인데, 어떠한 경험(데이터)으로부터 무언가를 스스로 학습하고 발전하는 시스템이라고 보면 된다.
그 시스템에는 여러 구성 요소 혹은 방법이 있을 것이고, 그 예로 `SVM(Support Vector Machine), Random Forest` 등이 있다.
그렇다면 `딥러닝(Deep Learning)`이란 무엇인가. 머신러닝은 일정량의 데이터를 넘어가면 학습효율이 잘 나오지 않는다[<sup id="fn1-back">1</sup>](#fn1)<sup>,</sup>[<sup id="fn2-back">2</sup>](#fn2).
딥러닝은 Neural Network를 무수히 많이 쌓아올려서 만들어진, 마치 인간의 신경시스템을 모방한 시스템이다. 이러한 AI 환경속에서, 어떠한 데이터로부터 유의미한 고찰을 도출해내는 것을 `데이터 사이언스`라고 말할 수 있다.

<center>
	<figure style="width: 60%"> <img src="/Images/Study/base2.png" alt="ML vs DL" />
    <figcaption>머신러닝 vs 딥러닝</figcaption>
    </figure>
</center>

앞으로는 딥러닝, 특히 `Computer Vision` 계열의 딥러닝 모델들을 알아보도록 하자. `자연어처리(NLP, Natural Language Processing)`나 다른 모델들도 많지만, 가장 많이 알려져있고, 학습하기 좋은 환경은 역시 Computer Vision 인 것 같다. CV 계열의 기술의 꽃은 역시 `합성곱 신경망, CNN(Convolutional Neural Network)`이지 않을까 싶다.

## 딥러닝 공부에 앞서
딥러닝 공부하기에 앞서, 필요한 개념들을 짚고 가기로 하자. 이유는? 
모델링할때 개념을 제대로 알지 못하면, 간단한 장난감 만드는것은 가능하겠지만,
정말 깊이 있는 모델링에 있어서는 한계에 부딪힐 것이다.
인공지능은 거창한 개념이 아닐 수도 있다. 인공지능을 학습할 때, 가장 중요하다고 생각되는 것은 `미적분`과 `선형대수`이다.
수많은 모델에서 학습이라는 개념은 가중치와 편향치를 갱신해서 오차를 줄여 나가는 과정이라고 볼 수 있다.
따라서 주로 이론적인 부분을 위주로 정리하며 글을 써나갈 것이다.

```python
import tensorflow as tf
mnist = tf.keras.datasets.mnist.load_data()
(x_train, y_train), (x_test, y_test) = mnist
print(x_train.shape, y_train.shape) # (60000, 28, 28) (60000,)
print(x_test.shape, y_test.shape) # (10000, 28, 28) (10000,)

# Reshape data dimension
x_train = x_train.reshape(x_train.shape[0], -1) # (60000, 784)
x_test = x_test.reshape(x_test.shape[0], -1) # (10000, 784)
mysvm = svm.SVC() # Define basic svm model
mysvm.fit(x_train, y_train) # training data with array of 1d data
y_predict = mysvm.predict(x_test)
result_f1 = f1_score(y_test, y_predict, average='micro')
# f1_score = 2 * (precision * recall) / (precision + recall)
print(result_f1) # 0.9792
```

위 코드는 숫자에 대한 필기 이미지 데이터를 구분하는 Support Vector Machine 모델이다. 괜히 python의 강점이 open source라고 부르는게 아닌 것을 알 수 있다.
15줄 남짓한 코드로, 약 98%의 성능을 내는 숫자 인식 모델을 개발한 것이다. Traditional machine learning model은 주로 scikit-learn 라이브러리를 이용하는데, 딥러닝 모델도 이와 크게 다르지 않다. 
Keras API를 이용하면 CNN model도 엇비슷하게 만들 수 있다.

그럼 이 때 문제점은 무엇일까? High-level에서 위에 내가 만든 모델은 진짜 장난감 코드이다. 현실의 데이터를 대상으로 사용하면 아마 data quality가 낮거나, data quantity가 충분하지 않거나, 아니면 다른 수많은 문제로 인해 성능이 형편없을지도 모른다. 오히려 성능이 잘나오면 의심을 해봐야할 정도이다.

Scikit-learn도, keras도 high-level api이다. 물론 이 환경에서도 세팅과 데이터 preprocessing 등 많은 것들을 고려해주면, 좋은 성능을 이끌어 낼 수도 있다.
그러나 내 경험상 high-level의 가장 큰 단점은, `이론을 제대로 알지 못한다` 이다. 실제로 나는 학, 석사 과정동안 모델들을 매일같이 접했는데, 이론을 제대로 모르고 썼다.
이론이 중요하다라는 생각은 했지만, 부족한 부분은 교수님의 지도로 커버했던 느낌이라고 생각한다.

나도 모르는게 엄청 많고, 늘 구글링을 끼고 산다
내가 현재 가장 절실하게 느끼는 것은, 현실에서 내가 멋들어진 모델을 만들려면 관련 이론을 습득해서 완전히 내것으로 만들어야겠다는 것이다.
나는 지금 전공과는 다른 회사에서 전문연구요원으로 있으면서 GPU CUDA 병렬화 업무를 한다. 딥러닝은 퇴근하고 공부하는 중이다. 내 목표는 합성곱 신경망의 CUDA 코드를 직접 짜보는 것이다.

다들 이론 공부 열심히!

## References
[<sup id="fn1">1</sup>](#fn1-back) <https://www.sumologickorea.com/blog/machine-learning-deep-learning/>  
[<sup id="fn2">2</sup>](#fn2-back) Laqtib, Safaa & El Yassini, Khalid & Hasnaoui, Moulay. (2020). Evaluation of Deep Learning Approaches for Intrusion Detection System in MANET. 10.1007/978-3-030-37629-1_71.
