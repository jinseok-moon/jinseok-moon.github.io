---
title: "Deep Residual Learning for Image Recognition"
excerpt: "ResNet"
categories:
  - Study
tags: [CNN, ResNet, Neural Network, Paper]
toc: true
toc_sticky: true
toc_label: "On this page"
published: false
use_math: true

date: 2022-04-16
last_modified_at: 2022-04-16
---

## [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)
ResNet으로 알려진 CNN 네트워크 논문이다. 기존의 네트워크들은 깊게 구성하여 파라미터가 많아지고 이로인해 Graident Vanishing Problem이 존재하는데, ResNet은 Residual Block 을 이용하여 이러한 문제점을 해결해준다고 한다. ResNetXX 로 이름이 붙어있으며, 네트워크의 깊이에 따라 Basic Block / BottleNeck Block 을 이용한다.

```python
class BasicBlock(nn.Module):
    mul = 1

    def __init__(self, in_dim, out_dim, stride=1):
        super(BasicBlock, self).__init__()

        self.conv1 = nn.Conv2d(in_dim, out_dim, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_dim)

        # stride = 1, padding = 1이므로, 너비와 높이는 항시 유지됨
        self.conv2 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_dim)

        # x를 그대로 더해주기 위함
        self.shortcut = nn.Sequential()

        # 만약 size가 안맞아 합연산이 불가하다면, 연산 가능하도록 모양을 맞춰줌
        if stride != 1:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_dim, out_dim, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_dim)
            )

    def forward(self, x):
        out = self.conv1(x)
        out = self.bn1(out)
        out = F.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out += self.shortcut(x)  # F(x) + x
        out = F.relu(out)
        return out
```