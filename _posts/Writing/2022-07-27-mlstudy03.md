---
title: "머신러닝 공부 03 - 소프트맥스 회귀"
categories:
  - Study
tags: [AI, Pytorch, Machine Learning]
toc: true
toc_sticky: true
toc_label: "On this page"
published: false
use_math: true

date: 2022-07-18
last_modified_at: 2022-07-18
---

## 소프트맥스 회귀
선형 회귀와 로지스틱 회귀까지 알아봤습니다. 로지스틱 회귀를 이용해서 Yes/No, True/False, 강아지/고양이 와 같이 두 개의 라벨로 나눌 수 있는 이진 분류 (Binary Classification) 문제를 풀 수 있었습니다. 하지만 강아지와 고양이에 더해서 기린, 호랑이 등 여러 라벨을 가지는 문제에 대해서는 로지스틱 회귀로 풀기 어려웠습니다. 이렇게 세 개 이상의 선택지로부터의 분류 문제를 풀기 위해서는 `소프트맥스 회귀 (Softmax Regression)` 을 이용하게 됩니다. 소프트맥스 회귀는 $$k$$ 차원의 데이터로부터 $$k$$ 개의 각 클래스에 대한 확률을 추정합니다. a, b, c 라는 세 개의 클래스가 있다고 했을때, 이에 대해서 softmax regression을 적용하면 다음과 같습니다.

$$
\begin{equation}
p_i = \frac{e^{z_i}}{\sum^k_{j=1}e^{z_j}}
\end{equation}
$$

$$
\begin{equation}
softmax(z) = \left[ p_1, p_2, p_3 \right] = \left[ p_{a}, p_{b}, p_{c} \right] 
\end{equation}
$$

<center>
<figure style="width:50%"> <img src="/Images/Study/mlstudy/3/softmax.jpg" alt=""/>
<figcaption>Softmax Regression</figcaption>
</figure>
</center>

<center>
<figure style="width:50%"> <img src="/Images/Study/mlstudy/3/matrix.jpg" alt=""/>
<figcaption>Matrix 표현</figcaption>
</figure>
</center>

입력 차원이 5개인 데이터에 대해서는, softmax 함수의 input 으로 사용하기 위해서, $$z$$ 차원수를 맞춰 가중치 곱을 수행합니다. 이렇게 해서 얻어진 $$z$$ 를 이용해서 softmax 함수를 거치면 최종적으로 각 클래스에 대한 확률이 나오게 됩니다. 

## 손실 함수
로지스틱 회귀에서는 0~1 사이의 확률로, 0.5를 기준으로 이진 분류를 수행했습니다. 이번엔 클래스가 세 개가 되었는데, 이 경우에는 어떻게 해야 손실값을 구할 수 있을까요? 먼저 a, b, c 클래스를 `원-핫 인코딩 (One-Hot Encoding)` 기법을 통해 변환을 해주겠습니다. 원-핫 인코딩은 각각의 클래스를 벡터로 만들어주는 기법으로, 그림으로 나타내면 알기 쉽습니다.

<center>
<figure style="width:50%"> <img src="/Images/Study/mlstudy/3/one-hot.jpg" alt=""/>
<figcaption>One-Hot Encoding</figcaption>
</figure>
</center>

이렇게 원-핫 벡터로 나타내게 되면, 로지스틱 회귀에서 수행했던 것처럼 손실값을 구할 수 있습니다. 그리고 이 손실값을 각 클래스에 대해서 모두 구해서 더해주면 되는데, 이 손실 함수를 `크로스 엔트로피 (Cross Entropy) 함수` 라고 합니다.

$$
\begin{equation}
\mathcal{L}(W) = -\sum_{j=1}^{k}y_{j}\ log(p_{j})
\end{equation}
$$
